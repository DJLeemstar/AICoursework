{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data inporting and setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''imports and setting up our plot as well as dataset setup'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn import model_selection\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "dataset = pd.read_csv(\"breast_cancer.csv\")\n",
    "# preprocessing of data\n",
    "dataset.replace('?', -99999, inplace=True)\n",
    "# get all the data into columns\n",
    "columns = dataset.columns.tolist()\n",
    "# remove class and id as they have no effect on the prediction\n",
    "columns = [c for c in columns if c not in [\"Class\", \"ID\"]]\n",
    "# storing the variable we will prredict with\n",
    "target = 'Class'\n",
    "\n",
    "X = dataset[columns]\n",
    "y = dataset[target]\n",
    "y = y.map({2: 0, 4: 1})\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Accuracy:  98.31919243547149 \n",
      "Mean Training Precision:  0.9609596423109823 \n",
      "Mean Training Recall:  0.9916990500863558 \n",
      "Mean Training F1 Score:  0.9760415668173797 \n",
      "Mean Validation Accuracy:  95.42651593011306 \n",
      "Mean Validation Precision:  0.9425372866127584 \n",
      "Mean Validation Recall:  0.9252551020408163 \n",
      "Mean Validation F1 Score:  0.9323327327819282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gradient_boosting_model = GradientBoostingClassifier(learning_rate=0.05, n_estimators=72, max_depth=5, min_samples_split=50,\n",
    "                                       min_samples_leaf=5, subsample=0.8, random_state=10, max_features=3, warm_start=True)\n",
    "    # learning_rate = determines the impact of each tree on the final outcome, low values preferred to make tree robust but need more trees (n_estimators) to model all the relations\n",
    "    # n_estimators = number of sequential trees to be modeled, can cause over-fitting so it should be balanced with learning rate\n",
    "    # max_depth = maximum depth of a tree, higher depth -> more specific -> over-fitting, only ~ 560 samples so low end number 5\n",
    "    # min_samples_split = minimum number of samples required in a node to be splitted, ~ 0.5-1% of samples\n",
    "    # min_samples_leaf = minimum number of samples required in a leaf, ~ a 10th of split\n",
    "    # subsample =  fraction (%) of observations to be selected for each tree, between 0.7 and 1 are good, strengthening values\n",
    "    # random_state = random number seed so that same random numbers are generated every time, if not fixed -> different outcomes for subsequent runs\n",
    "    # max_features = number of features to consider while searching for best split, 30-40% of total features, higher value -> CAN cause over-fitting\n",
    "    # warm_start = fit additional trees on previous fits of a model, can use it to increase the number of estimators in small steps and test different values without having to run from scratch\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = model_selection.cross_validate(\n",
    "        estimator=gradient_boosting_model, X=X, y=y, cv=5, scoring=scoring, return_train_score=True)\n",
    "print(\"Mean Training Accuracy: \", results['train_accuracy'].mean()*100,\n",
    "          \"\\nMean Training Precision: \", results['train_precision'].mean(),\n",
    "          \"\\nMean Training Recall: \", results['train_recall'].mean(),\n",
    "          \"\\nMean Training F1 Score: \", results['train_f1'].mean(),\n",
    "          \"\\nMean Validation Accuracy: \", results['test_accuracy'].mean()*100,\n",
    "          \"\\nMean Validation Precision: \", results['test_precision'].mean(),\n",
    "          \"\\nMean Validation Recall: \", results['test_recall'].mean(),\n",
    "          \"\\nMean Validation F1 Score: \", results['test_f1'].mean()\n",
    "          )\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funciton to test the seperate parameters and their results on the train time and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, param = 'n_estimators', name = 'Num Trees'):\n",
    "    param_name = 'param_%s' % param\n",
    "    \n",
    "    # Extract information from the cross validation model\n",
    "    test_scores = model.cv_results_['mean_test_score']\n",
    "    train_time = model.cv_results_['mean_fit_time']\n",
    "    param_values = list(model.cv_results_[param_name])\n",
    "    \n",
    "    # Plot the scores over the parameter\n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    plt.subplot(121)\n",
    "    \n",
    "\n",
    "    plt.plot(param_values, test_scores, '-', label = 'test')\n",
    "    plt.ylim(ymin = -0.5, ymax = 0)\n",
    "    plt.legend()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Neg Mean Absolute Error')\n",
    "    plt.title('Score vs %s' % name)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(param_values, train_time, '-')\n",
    "    plt.ylim(ymin = 0.0, ymax = 1.25)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Train Time (sec)')\n",
    "    plt.title('Training Time vs %s' % name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout(pad = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to evaluate the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50} 0.9951735825449062\n"
     ]
    }
   ],
   "source": [
    "#perform first grid search to tune our learning rate to the number of trees as these are linked\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_test1 = {'n_estimators':range(10,81,10)}\n",
    "grid_search_num_trees = GridSearchCV(estimator = GradientBoostingClassifier(),\n",
    "param_grid = param_test1,scoring= 'roc_auc', n_jobs=-1, cv=5)\n",
    "grid_search_num_trees.fit()\n",
    "\n",
    "print( grid_search_num_trees.best_params_, grid_search_num_trees.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'min_samples_split': 201}, 0.9964754730563555)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':range(1,10,2), 'min_samples_split':range(1,600,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch2.fit(x_train,y_train)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_features': 9}, 0.9952753068010421)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':range(7,20,2)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,max_depth=3, min_samples_split=200, min_samples_leaf=60, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,cv=5)\n",
    "gsearch4.fit(x_train,y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
